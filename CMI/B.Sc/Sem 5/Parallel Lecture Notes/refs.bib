@incollection{karpramachandran,
title = {CHAPTER 17 - Parallel Algorithms for Shared-Memory Machines},
editor = {JAN {VAN LEEUWEN}},
booktitle = {Algorithms and Complexity},
publisher = {Elsevier},
address = {Amsterdam},
pages = {869-941},
year = {1990},
series = {Handbook of Theoretical Computer Science},
isbn = {978-0-444-88071-0},
doi = {https://doi.org/10.1016/B978-0-444-88071-0.50022-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780444880710500229},
author = {Richard M. KARP and Vijaya RAMACHANDRAN},
abstract = {Publisher Summary
This chapter discusses parallel algorithms for shared-memory machines. Parallel computation is rapidly becoming a dominant theme in all areas of computer science and its applications. It is estimated that, within a decade, virtually all developments in computer architecture, systems programming, computer applications and the design of algorithms will be taking place within the context of parallel computation. In preparation for this revolution, theoretical computer scientists have begun to develop a body of theory centered on parallel algorithms and parallel architectures. As there is no consensus yet on the appropriate logical organization of a massively parallel computer, and as the speed of parallel algorithms is constrained as much by limits on interprocessor communication as it is by purely computational issues, it is not surprising that a variety of abstract models of parallel computation have been pursued. Closest to the hardware level are the VLSI models, which focus on the technological limits of today's chips, in which gates and wires are packed into a small number of planar layers.}
}

@Inbook{akssortparallel,
	editor="Padua, David",
	title="Ajtai--Koml{\'o}s--Szemer{\'e}di Sorting Network",
	bookTitle="Encyclopedia of Parallel Computing",
	year="2011",
	publisher="Springer US",
	address="Boston, MA",
	pages="16--16",
	isbn="978-0-387-09766-4",
	doi="10.1007/978-0-387-09766-4_2379",
	url="https://doi.org/10.1007/978-0-387-09766-4_2379"
}
@Inbook{VollmerCh2,
	author="Vollmer, Heribert",
	title="Relations to Other Computation Models",
	bookTitle="Introduction to Circuit Complexity: A Uniform Approach",
	year="1999",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="35--78",
	abstract="The results of the previous chapter show that there is a circuit complexity class which contains every length-respecting function f : {\{}0,1{\}}* {\textrightarrow} {\{}0,1{\}}*, computable or not:",
	isbn="978-3-662-03927-4",
	doi="10.1007/978-3-662-03927-4_3",
	url="https://doi.org/10.1007/978-3-662-03927-4_3"
}
@article{ac1crcwstockmeyervishkin,
	author = {Stockmeyer, Larry and Vishkin, Uzi},
	title = {Simulation of Parallel Random Access Machines by Circuits},
	journal = {SIAM Journal on Computing},
	volume = {13},
	number = {2},
	pages = {409-422},
	year = {1984},
	doi = {10.1137/0213027},
	URL = {https://doi.org/10.1137/0213027},
	eprint = {https://doi.org/10.1137/0213027},
	abstract = { A relationship is established between (i) parallel random-access machines that allow many processors to concurrently read from or write into a common memory including simultaneous reading or writing into the same memory location (CROW PRAM), and (ii) combinational logic circuits that contain AND’s, OR’s and NOT’s, with no bound placed on the fan-in of AND-gates and OR-gates. Parallel time and number of processors for CROW PRAM’s are shown to correspond respectively (and simultaneously) to depth and size for circuits, where the time-depth correspondence is to within a constant factor and the processors-size correspondence is to within a polynomial. By applying a recent result of Furst, Saxe and Sipser, we obtain the corollary that parity, integer multiplication, graph transitive closure and integer sorting cannot be computed in constant time by a CROW PRAM with a polynomial number of processors. This is the first nonconstant lower bound on the parallel time required to solve these problems by a CROW PRAM with a polynomial number of processors. We also state and outline the proof of a similar result, due to W. L. Ruzzo and M. Tompa, that relates time and processor bounds for CRCW PRAM’S to alternation and space bounds for alternating Turing machines. }
}

@article{dyckbarrington,
	title = {On the relative complexity of some languages in NC1},
	journal = {Information Processing Letters},
	volume = {32},
	number = {5},
	pages = {251-256},
	year = {1989},
	issn = {0020-0190},
	doi = {https://doi.org/10.1016/0020-0190(89)90052-5},
	url = {https://www.sciencedirect.com/science/article/pii/0020019089900525},
	author = {David A. {Mix Barrington} and James Corbett},
	keywords = {Computational complexity, formal languages},
	abstract = {We consider the relative complexity of a number of languages known to be in uniform NC1, using the descriptive framework of Barrington, Immerman, and Straubing (1988). In particular, we sharpen several results of Ibarra, Jiang, and Ravikumar (1988). We show that the one-sided Dyck languages, structured CFL's, and bracketed CFL's are recognizable by very uniform families of threshold circuits (are in DLOGTIME-uniform TC0). We show that a large class of deterministic linear CFL's are in uniform TC0, but that some are complete for uniform NC1 (and thus not in uniform TC0 unless TC0 = NC1 in the uniform setting).}
}